# 11.03 Микросервисы: подходы

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

---

**Ответ**:

### Gitlab + Vault by HashiCorp или SecretHub + Docker

![gitlab-image](assets/gitlab.png)

Gitlab можно развернуть как на своих вычислительных мощностях, в облаке или SaaS.

#### Gitaly - работа с репозиториями

В Gitlab есть **Gitaly** - это внутренний сервис, который, грубо говоря, отвечает за взаимодействие web-морды(то что все видят) с Git.
**Gitaly** предоставляет API для web, строит хранилища репозиториев используя Git, короче под капотом управляет тем что мы используем
и видим в Gitlab'e.

#### gitlab-ci.yml - конфигурация пайплайнов

Конфигурация сборок осуществляется в файле **.gitlab-ci.yml**, который нужно расположить в корне проекта.
В нем можно описать правила(триггеры) на которые нужно запускать сборку проектов.
Можно также настроить глубже и описать триггеры для монорепозиториев, которые будут запускать деплои на уровне изменений
в каталогах.

**.gitlab-ci.yml** не имеет жесткой структуры, можно спокойно описать нужные кастомные шаги пайплайна(stages).

#### Gitlab-Runners - агенты сборки

Агенты сборки в Gitlab называются **Gitlab-Runner's**. Их рекомендуется размещать на отдельных от Gitlab-хостах, для
больших компаний можно использовать для этой цели Kubernetes. В агентах в принципе можно делать что угодно на этапе
отработки пайплайна, но обычно в продуктах с микросервисной архитектурой собирают проект, прогоняют тесты, собирают контейнер
и пушат его в docker-registry.

И конечно же агентам можно прописать [concurrent](https://docs.gitlab.com/runner/fleet_scaling/) и запускать по 
несколько штук одновременно.

#### Vault by HashiCorp или SecretHub - хранение секретов

Gitlab поддерживает из коробки только переменные. В целом для многих команд этого уже достаточно, но не для компаний с 
чувствительными данными. Финансовые организации, госсектор, компании работающие в сфере здравоохранения и просто компании
в которых есть DevSecOps-культура не могут позволить хранить всякие токены, ключи и пароли в открытом для всех
разработчиков доступе, поэтому можно интегрироваться с внешними инструментами хранения sensitive-data.

Как-то так =)

---

В принципе я мог бы написать еще про **Microsoft Azure DevOps** и другие облака, но это уже другая история.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

---

**Ответ**:

### ElasticSearch + Logstash + Kibana + Filebeat

![elk-stack-image](assets/elk-stack.png)

Вообще в целом все сервисы этого стека принадлежат и скачиваются из сайта компании [Elastic](https://www.elastic.co).

#### ElasticSearch - центральное хранилище

Изначально Elastic это поисковой движок(на базе Apache Lucene), который позволяет хранить и осуществлять полнотекстовой 
поиск в структурированных данных.

Почему и когда он стал популярен и стандартом в задачах DevOps в целях сборов и работы с логами для меня 
небольшая загадка, но в целом логическое объяснение этому есть - не так много бизнес-задач и проектов где нужен полнотекстовой
поиск именно для продукта. В то же время для работы с логами, которых очень много и процесс хранения должен быть в любом
хорошем продукте, это очень нужно. Конечно же это не отменяет его уместное использование в крупных интернет-магазинах и 
других проектах где много текстовых данных.

Elastic в поставленной выше задаче будет выступать в роли центрального хранилища. Он масштабируется горизонтально,
за счет индексов поддерживает полнотекстовой поиск и относительно простой, ранее был полный OpenSource со свободной лицензией,
с 7.10.2 версии сделали его с закрытой лицензией.

Мы его настраивали в одном из [домашних заданий](https://github.com/sahaviev/netology-devops/blob/master/2-virt-homeworks/6.5-ELASTICSEARCH/6.5-ELASTICSEARCH.md)
по базам данных и анализировали причины деградации и т.д.

#### Logstash - коллектор данных

LogStash - это сервис, который выполняет роль коллектора данных.

Данные от сервисов нужно принять и сохранить, желательно так, чтобы было понятно откуда, от кого и когда пришли данные. 

Если это будут делать все сервисы напрямую(хотя это можно сделать с тем же Filebeat), 
они должны будут делать много лишней работы: определять нужный формат данных, следовать структуре ElasticSearch и 
отправлять эти данные в Elastic, зачастую это вообще может быть невозможным со стороны источника данных +
в микросервисной архитектуре не очень хорошо когда один сервис решает много задач, поэтому для этой задачи разработали LogStash.

Он принимает от сервисов логи в сыром виде, фильтрует их, насыщает дополнительной информацией и сохраняет в нужном виде в ElasticSearch.

#### Kibana - веб-интерфейс

Kibana - это сервис, который взаимодействует с ElasticSearch, а точнее использует его как источник данных.

Она позволяет создавать различные динамические дашборды(панели мониторинга, таблицы, графики и диаграммы),
для данных из ElasticSearch, которые будут обновляться в режиме реального времени.

Kibana дает возможно удобно фильтровать и искать нужные данные.
И этими дашбордами можно обмениваться просто скопировав ссылку в адресной строке браузера.

#### Filebeat - инструмент сборки логов в инстансах

Filebeat - это сервис, который собирает логи в источниках данных. Он умеет считывать файлы логов или их хвосты(tail), 

У него есть два компонента это поисковики(inputs) и сборщики(harvesters). Поисковики анализируют файлы и цепляют к ним
сборщиков. Сборщики читают файлы, сохраняет прогресс чтения на случай если по какой-то причине(например, обновление)
они будут отключены, сборщики смогут продолжить читать файлы с того места где остановились, что позволит избежать потери данных.

Отдельно стоит отметить что на уровне операционной системы файлы логов блокируются и даже если они будут удалены
(сервисом который их пишет для того чтобы в системе не закончилось свободное место), данные из
логов не будут потеряны, до тех пор пока они не будут считаны и отправлены в output(Logstash/ElasticSearch).

У Filebeat из коробки идут несколько модулей, которые умеют работать с логами(audit, Apache, Nginx, System и MySQL).

Собственно все это делает его важным инструментом в стеке ELK, который решает в т.ч. вопрос гарантии доставки логов.

---

Я к сожалению не шибко эксперт в сопровождении и настройки инструментов логирования. 
Чаще всего, там где работал, использовали именно этот стек и я был в лучшем случае developer-user данных систем.


## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения: 

Docker-compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл запустив который можно перейти по адресу http://localhost:8081 по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---